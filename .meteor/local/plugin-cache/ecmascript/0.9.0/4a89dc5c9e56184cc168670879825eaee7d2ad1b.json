{"metadata":{"usedHelpers":[],"marked":[],"modules":{"imports":[{"source":"meteor/meteor","imported":["Meteor"],"specifiers":[{"kind":"named","imported":"Meteor","local":"Meteor"}]},{"source":"meteor/underscore","imported":["_"],"specifiers":[{"kind":"named","imported":"_","local":"_"}]},{"source":"meteor/random","imported":["Random"],"specifiers":[{"kind":"named","imported":"Random","local":"Random"}]},{"source":"meteor/ostrio:files","imported":["FilesCollection"],"specifiers":[{"kind":"named","imported":"FilesCollection","local":"FilesCollection"}]},{"source":"stream","imported":["default"],"specifiers":[{"kind":"named","imported":"default","local":"stream"}]},{"source":"meteor/session","imported":["Session"],"specifiers":[{"kind":"named","imported":"Session","local":"Session"}]},{"source":"aws-sdk/clients/s3","imported":["default"],"specifiers":[{"kind":"named","imported":"default","local":"S3"}]},{"source":"fs","imported":["default"],"specifiers":[{"kind":"named","imported":"default","local":"fs"}]},{"source":"/imports/dashboard/product/addNewProduct/api/projectSettings.js","imported":["ProjectSettings"],"specifiers":[{"kind":"named","imported":"ProjectSettings","local":"ProjectSettings"}]}],"exports":{"exported":[],"specifiers":[]}}},"options":{"filename":"imports/dashboard/product/addNewProduct/imageUploadServer/ProductImage.js","filenameRelative":"imports/dashboard/product/addNewProduct/imageUploadServer/ProductImage.js","env":{"development":{"plugins":[]}},"retainLines":false,"highlightCode":true,"suppressDeprecationMessages":false,"presets":[],"plugins":[[[],{"generateLetDeclarations":true,"enforceStrictMode":false}],[[],null],[[],{"polyfill":false}],[[],null],[[],null],[[],null],[[],{"allowTopLevelThis":true,"strict":false,"loose":true}],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],{"loose":true}],[[],{"loose":true}],[[],null],[[],{"loose":true}],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],{"loose":true}],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null],[[],null]],"ignore":[],"code":true,"metadata":true,"ast":true,"comments":true,"compact":false,"minified":false,"sourceMap":true,"sourceMaps":true,"sourceMapTarget":"imports/dashboard/product/addNewProduct/imageUploadServer/ProductImage.js.map","sourceFileName":"imports/dashboard/product/addNewProduct/imageUploadServer/ProductImage.js","babelrc":false,"sourceType":"module","moduleIds":false,"passPerPreset":false,"parserOpts":false,"generatorOpts":false,"basename":"ProductImage"},"ignored":false,"code":"var Meteor = void 0;\nmodule.watch(require(\"meteor/meteor\"), {\n    Meteor: function (v) {\n        Meteor = v;\n    }\n}, 0);\n\nvar _ = void 0;\n\nmodule.watch(require(\"meteor/underscore\"), {\n    _: function (v) {\n        _ = v;\n    }\n}, 1);\nvar Random = void 0;\nmodule.watch(require(\"meteor/random\"), {\n    Random: function (v) {\n        Random = v;\n    }\n}, 2);\nvar FilesCollection = void 0;\nmodule.watch(require(\"meteor/ostrio:files\"), {\n    FilesCollection: function (v) {\n        FilesCollection = v;\n    }\n}, 3);\nvar stream = void 0;\nmodule.watch(require(\"stream\"), {\n    \"default\": function (v) {\n        stream = v;\n    }\n}, 4);\nvar Session = void 0;\nmodule.watch(require(\"meteor/session\"), {\n    Session: function (v) {\n        Session = v;\n    }\n}, 5);\nvar S3 = void 0;\nmodule.watch(require(\"aws-sdk/clients/s3\"), {\n    \"default\": function (v) {\n        S3 = v;\n    }\n}, 6);\nvar fs = void 0;\nmodule.watch(require(\"fs\"), {\n    \"default\": function (v) {\n        fs = v;\n    }\n}, 7);\nvar ProjectSettings = void 0;\nmodule.watch(require(\"/imports/dashboard/product/addNewProduct/api/projectSettings.js\"), {\n    ProjectSettings: function (v) {\n        ProjectSettings = v;\n    }\n}, 8);\nvar s3Data = ProjectSettings.findOne({\n    \"_id\": \"1\"\n});\n\nif (s3Data) {\n    process.env.S3 = '{\"s3\":{\"key\": \"' + s3Data.key + '\", \"secret\": \"' + s3Data.secret + '\", \"bucket\": \"' + s3Data.bucket + '\", \"region\": \"' + s3Data.region + '\"}}';\n\n    if (process.env.S3) {\n        Meteor.settings.s3 = JSON.parse(process.env.S3).s3; // console.log(Meteor.settings.s3);\n\n        var s3Conf = Meteor.settings.s3 || {};\n        var bound = Meteor.bindEnvironment(function (callback) {\n            return callback();\n        }); // Check settings existence in `Meteor.settings`\n        // This is the best practice for app security\n\n        if (s3Conf && s3Conf.key && s3Conf.secret && s3Conf.bucket && s3Conf.region) {\n            module.export({\n                ProductImage: function () {\n                    return ProductImage;\n                }\n            });\n            // Create a new S3 object\n            //s3Conf.secret,\n            //s3Conf.key,\n            //s3Conf.region,\n            var s3 = new S3({\n                secretAccessKey: s3Conf.secret,\n                accessKeyId: s3Conf.key,\n                region: s3Conf.region,\n                // sslEnabled: true, // optional\n                httpOptions: {\n                    timeout: 60000,\n                    agent: false\n                }\n            }); // console.log('s3: ', s3);\n            // Declare the Meteor file collection on the Server\n\n            var ProductImage = new FilesCollection({\n                debug: false,\n                // Change to `true` for debugging\n                storagePath: 'ProductImage',\n                collectionName: 'ProductImage',\n                // Disallow Client to execute remove, use the Meteor.method\n                allowClientCode: false,\n                chunkSize: 1024 * 1024,\n                // Start moving files to AWS:S3\n                // after fully received by the Meteor server\n                onAfterUpload: function (fileRef) {\n                    var _this = this;\n\n                    // Run through each of the uploaded file\n                    // console.log(\"fileRef2: \", fileRef);\n                    _.each(fileRef.versions, function (vRef, version) {\n                        // We use Random.id() instead of real file's _id\n                        // to secure files from reverse engineering on the AWS client\n                        var filePath = 'ProductImage/' + fileRef._id + '.' + fileRef.extension; // console.log(\"filePath: \", filePath);\n                        // Create the AWS:S3 object.\n                        // Feel free to change the storage class from, see the documentation,\n                        // `STANDARD_IA` is the best deal for low access files.\n                        // Key is the file name we are creating on AWS:S3, so it will be like files/XXXXXXXXXXXXXXXXX-original.XXXX\n                        // Body is the file stream we are sending to AWS\n\n                        s3.putObject({\n                            // ServerSideEncryption: 'AES256', // Optional\n                            StorageClass: 'STANDARD',\n                            Bucket: s3Conf.bucket,\n                            //s3Conf.bucket,\n                            Key: filePath,\n                            Body: fs.createReadStream(vRef.path),\n                            ContentType: vRef.type\n                        }, function (error) {\n                            // console.log(\"error: \", error);\n                            bound(function () {\n                                if (error) {\n                                    console.error(error);\n                                } else {\n                                    // Update FilesCollection with link to the file at AWS\n                                    var upd = {\n                                        $set: {}\n                                    };\n                                    upd['$set']['versions.' + version + '.meta.pipePath'] = filePath; // console.log(\"upd: \", upd);\n\n                                    _this.collection.update({\n                                        _id: fileRef._id\n                                    }, upd, function (updError) {\n                                        if (updError) {\n                                            // console.log(\"updError: \", updError);\n                                            console.error(updError);\n                                        } else {\n                                            // Unlink original files from FS after successful upload to AWS:S3\n                                            // console.log(\"unlink: \", fileRef._id);\n                                            _this.unlink(_this.collection.findOne(fileRef._id), version);\n                                        }\n                                    });\n                                }\n                            });\n                        });\n                    });\n                },\n                // Intercept access to the file\n                // And redirect request to AWS:S3\n                interceptDownload: function (http, fileRef, version) {\n                    // console.log('interceptDownload');\n                    var path = void 0;\n\n                    if (fileRef && fileRef.versions && fileRef.versions[version] && fileRef.versions[version].meta && fileRef.versions[version].meta.pipePath) {\n                        path = fileRef.versions[version].meta.pipePath;\n                    }\n\n                    if (path) {\n                        // console.log('path ',path);\n                        // If file is successfully moved to AWS:S3\n                        // We will pipe request to AWS:S3\n                        // So, original link will stay always secure\n                        // To force ?play and ?download parameters\n                        // and to keep original file name, content-type,\n                        // content-disposition, chunked \"streaming\" and cache-control\n                        // we're using low-level .serve() method\n                        var opts = {\n                            Bucket: s3Conf.bucket,\n                            Key: path\n                        };\n\n                        if (http.request.headers.range) {\n                            var vRef = fileRef.versions[version];\n\n                            var range = _.clone(http.request.headers.range);\n\n                            var array = range.split(/bytes=([0-9]*)-([0-9]*)/);\n                            var start = parseInt(array[1]);\n                            var end = parseInt(array[2]);\n\n                            if (isNaN(end)) {\n                                // Request data from AWS:S3 by small chunks\n                                end = start + this.chunkSize - 1;\n\n                                if (end >= vRef.size) {\n                                    end = vRef.size - 1;\n                                }\n                            }\n\n                            opts.Range = \"bytes=\" + start + \"-\" + end;\n                            http.request.headers.range = \"bytes=\" + start + \"-\" + end;\n                        }\n\n                        var fileColl = this;\n                        s3.getObject(opts, function (error) {\n                            if (error) {\n                                console.error(error);\n\n                                if (!http.response.finished) {\n                                    http.response.end();\n                                }\n                            } else {\n                                // console.log(opts);\n                                if (http.request.headers.range && this.httpResponse.headers['content-range']) {\n                                    // Set proper range header in according to what is returned from AWS:S3\n                                    http.request.headers.range = this.httpResponse.headers['content-range'].split('/')[0].replace('bytes ', 'bytes=');\n                                }\n\n                                var dataStream = new stream.PassThrough(); // console.warn('fileColl ',fileColl);\n\n                                fileColl.serve(http, fileRef, fileRef.versions[version], version, dataStream);\n                                dataStream.end(this.data.Body);\n                            }\n                        });\n                        return true;\n                    } // While file is not yet uploaded to AWS:S3\n                    // It will be served file from FS\n\n\n                    return false;\n                }\n            });\n            // Intercept FilesCollection's remove method to remove file from AWS:S3\n            var _origRemove = ProductImage.remove;\n\n            ProductImage.remove = function (search) {\n                var cursor = this.collection.find(search);\n                cursor.forEach(function (fileRef) {\n                    _.each(fileRef.versions, function (vRef) {\n                        if (vRef && vRef.meta && vRef.meta.pipePath) {\n                            // Remove the object from AWS:S3 first, then we will call the original FilesCollection remove\n                            s3.deleteObject({\n                                Bucket: s3Conf.bucket,\n                                Key: vRef.meta.pipePath\n                            }, function (error) {\n                                bound(function () {\n                                    if (error) {\n                                        console.error(error);\n                                    }\n                                });\n                            });\n                        }\n                    });\n                }); //remove original file from database\n\n                _origRemove.call(this, search);\n            };\n        } else {\n            throw new Meteor.Error(401, 'Missing Meteor file settings');\n        }\n    }\n}","map":{"version":3,"sources":["imports/dashboard/product/addNewProduct/imageUploadServer/ProductImage.js"],"names":["Meteor","module","watch","require","v","_","Random","FilesCollection","stream","Session","S3","fs","ProjectSettings","s3Data","findOne","process","env","key","secret","bucket","region","settings","s3","JSON","parse","s3Conf","bound","bindEnvironment","callback","export","ProductImage","secretAccessKey","accessKeyId","httpOptions","timeout","agent","debug","storagePath","collectionName","allowClientCode","chunkSize","onAfterUpload","fileRef","each","versions","vRef","version","filePath","_id","extension","putObject","StorageClass","Bucket","Key","Body","createReadStream","path","ContentType","type","error","console","upd","$set","collection","update","updError","unlink","interceptDownload","http","meta","pipePath","opts","request","headers","range","clone","array","split","start","parseInt","end","isNaN","size","Range","fileColl","getObject","response","finished","httpResponse","replace","dataStream","PassThrough","serve","data","_origRemove","remove","search","cursor","find","forEach","deleteObject","call","Error"],"mappings":"AAAA,IAAIA,eAAJ;AAAWC,OAAOC,KAAP,CAAaC,QAAQ,eAAR,CAAb,EAAsC;AAACH,UAAD,YAAQI,CAAR,EAAU;AAACJ,iBAAOI,CAAP;AAAS;AAApB,CAAtC,EAA4D,CAA5D;;AAA+D,IAAIC,UAAJ;;AAAMJ,OAAOC,KAAP,CAAaC,QAAQ,mBAAR,CAAb,EAA0C;AAACE,KAAD,YAAGD,CAAH,EAAK;AAACC,YAAED,CAAF;AAAI;AAAV,CAA1C,EAAsD,CAAtD;AAAyD,IAAIE,eAAJ;AAAWL,OAAOC,KAAP,CAAaC,QAAQ,eAAR,CAAb,EAAsC;AAACG,UAAD,YAAQF,CAAR,EAAU;AAACE,iBAAOF,CAAP;AAAS;AAApB,CAAtC,EAA4D,CAA5D;AAA+D,IAAIG,wBAAJ;AAAoBN,OAAOC,KAAP,CAAaC,QAAQ,qBAAR,CAAb,EAA4C;AAACI,mBAAD,YAAiBH,CAAjB,EAAmB;AAACG,0BAAgBH,CAAhB;AAAkB;AAAtC,CAA5C,EAAoF,CAApF;AAAuF,IAAII,eAAJ;AAAWP,OAAOC,KAAP,CAAaC,QAAQ,QAAR,CAAb,EAA+B;AAAA,yBAASC,CAAT,EAAW;AAACI,iBAAOJ,CAAP;AAAS;AAArB,CAA/B,EAAsD,CAAtD;AAAyD,IAAIK,gBAAJ;AAAYR,OAAOC,KAAP,CAAaC,QAAQ,gBAAR,CAAb,EAAuC;AAACM,WAAD,YAASL,CAAT,EAAW;AAACK,kBAAQL,CAAR;AAAU;AAAtB,CAAvC,EAA+D,CAA/D;AAAkE,IAAIM,WAAJ;AAAOT,OAAOC,KAAP,CAAaC,QAAQ,oBAAR,CAAb,EAA2C;AAAA,yBAASC,CAAT,EAAW;AAACM,aAAGN,CAAH;AAAK;AAAjB,CAA3C,EAA8D,CAA9D;AAAiE,IAAIO,WAAJ;AAAOV,OAAOC,KAAP,CAAaC,QAAQ,IAAR,CAAb,EAA2B;AAAA,yBAASC,CAAT,EAAW;AAACO,aAAGP,CAAH;AAAK;AAAjB,CAA3B,EAA8C,CAA9C;AAAiD,IAAIQ,wBAAJ;AAAoBX,OAAOC,KAAP,CAAaC,QAAQ,iEAAR,CAAb,EAAwF;AAACS,mBAAD,YAAiBR,CAAjB,EAAmB;AAACQ,0BAAgBR,CAAhB;AAAkB;AAAtC,CAAxF,EAAgI,CAAhI;AAgBpmB,IAAIS,SAASD,gBAAgBE,OAAhB,CAAwB;AAAC,WAAM;AAAP,CAAxB,CAAb;;AACA,IAAGD,MAAH,EAAU;AACNE,YAAQC,GAAR,CAAYN,EAAZ,GAAe,oBAAmBG,OAAOI,GAA1B,GAA8B,gBAA9B,GAAgDJ,OAAOK,MAAvD,GAA8D,gBAA9D,GAAgFL,OAAOM,MAAvF,GAA+F,gBAA/F,GAAgHN,OAAOO,MAAvH,GAA8H,KAA7I;;AAGA,QAAIL,QAAQC,GAAR,CAAYN,EAAhB,EAAoB;AAChBV,eAAOqB,QAAP,CAAgBC,EAAhB,GAAqBC,KAAKC,KAAL,CAAWT,QAAQC,GAAR,CAAYN,EAAvB,EAA2BY,EAAhD,CADgB,CAEhB;;AACA,YAAMG,SAASzB,OAAOqB,QAAP,CAAgBC,EAAhB,IAAsB,EAArC;AACA,YAAMI,QAAS1B,OAAO2B,eAAP,CAAuB,UAACC,QAAD,EAAc;AAChD,mBAAOA,UAAP;AACH,SAFc,CAAf,CAJgB,CAQhB;AACA;;AACA,YAAIH,UAAUA,OAAOR,GAAjB,IAAwBQ,OAAOP,MAA/B,IAAyCO,OAAON,MAAhD,IAA0DM,OAAOL,MAArE,EAA6E;AA/BrFnB,mBAAO4B,MAAP,CAAc;AAACC,8BAAa;AAAA,2BAAIA,YAAJ;AAAA;AAAd,aAAd;AAgCY;AACA;AACA;AACA;AACA,gBAAMR,KAAK,IAAIZ,EAAJ,CAAO;AACdqB,iCAAsBN,OAAOP,MADf;AAEdc,6BAAsBP,OAAOR,GAFf;AAGdG,wBAAsBK,OAAOL,MAHf;AAId;AACAa,6BAAa;AACTC,6BAAU,KADD;AAETC,2BAAU;AAFD;AALC,aAAP,CAAX,CALyE,CAgBzE;AACA;;AACO,gBAAML,eAAe,IAAIvB,eAAJ,CAAoB;AAC5C6B,uBAAiB,KAD2B;AACpB;AACxBC,6BAAiB,cAF2B;AAG5CC,gCAAiB,cAH2B;AAI5C;AACAC,iCAAiB,KAL2B;AAM5CC,2BAAiB,OAAO,IANoB;AAQ5C;AACA;AACAC,6BAV4C,YAU9BC,OAV8B,EAUrB;AAAA;;AACnB;AACA;AACArC,sBAAEsC,IAAF,CAAOD,QAAQE,QAAf,EAAyB,UAACC,IAAD,EAAOC,OAAP,EAAmB;AACxC;AACA;AAEA,4BAAMC,WAAW,kBAAkBL,QAAQM,GAA1B,GAA+B,GAA/B,GAAqCN,QAAQO,SAA9D,CAJwC,CAKxC;AAEA;AACA;AACA;AACA;AACA;;AACA3B,2BAAG4B,SAAH,CAAa;AACT;AACAC,0CAAe,UAFN;AAGTC,oCAAe3B,OAAON,MAHb;AAG6B;AACtCkC,iCAAeN,QAJN;AAKTO,kCAAe3C,GAAG4C,gBAAH,CAAoBV,KAAKW,IAAzB,CALN;AAMTC,yCAAeZ,KAAKa;AANX,yBAAb,EAOG,UAACC,KAAD,EAAW;AACV;AACAjC,kCAAM,YAAM;AACR,oCAAIiC,KAAJ,EAAW;AACPC,4CAAQD,KAAR,CAAcA,KAAd;AACH,iCAFD,MAEO;AACH;AACA,wCAAME,MAAM;AAAEC,8CAAM;AAAR,qCAAZ;AACAD,wCAAI,MAAJ,EAAY,cAAcf,OAAd,GAAwB,gBAApC,IAAwDC,QAAxD,CAHG,CAIH;;AAEA,0CAAKgB,UAAL,CAAgBC,MAAhB,CAAuB;AACnBhB,6CAAKN,QAAQM;AADM,qCAAvB,EAEGa,GAFH,EAEQ,UAACI,QAAD,EAAc;AAClB,4CAAIA,QAAJ,EAAc;AACV;AACAL,oDAAQD,KAAR,CAAcM,QAAd;AACH,yCAHD,MAGO;AACH;AACA;AACA,kDAAKC,MAAL,CAAY,MAAKH,UAAL,CAAgBjD,OAAhB,CAAwB4B,QAAQM,GAAhC,CAAZ,EAAkDF,OAAlD;AACH;AACJ,qCAXD;AAYH;AACJ,6BAtBD;AAuBH,yBAhCD;AAiCH,qBA7CD;AA8CH,iBA3D2C;AA8D5C;AACA;AACAqB,iCAhE4C,YAgE1BC,IAhE0B,EAgEpB1B,OAhEoB,EAgEXI,OAhEW,EAgEF;AACtC;AACA,wBAAIU,aAAJ;;AAEA,wBAAId,WAAWA,QAAQE,QAAnB,IAA+BF,QAAQE,QAAR,CAAiBE,OAAjB,CAA/B,IAA4DJ,QAAQE,QAAR,CAAiBE,OAAjB,EAA0BuB,IAAtF,IAA8F3B,QAAQE,QAAR,CAAiBE,OAAjB,EAA0BuB,IAA1B,CAA+BC,QAAjI,EAA2I;AACvId,+BAAOd,QAAQE,QAAR,CAAiBE,OAAjB,EAA0BuB,IAA1B,CAA+BC,QAAtC;AACH;;AAED,wBAAId,IAAJ,EAAU;AACN;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA,4BAAMe,OAAO;AACTnB,oCAAQ3B,OAAON,MADN;AAETkC,iCAAQG;AAFC,yBAAb;;AAKA,4BAAIY,KAAKI,OAAL,CAAaC,OAAb,CAAqBC,KAAzB,EAAgC;AAC5B,gCAAM7B,OAAQH,QAAQE,QAAR,CAAiBE,OAAjB,CAAd;;AACA,gCAAI4B,QAAUrE,EAAEsE,KAAF,CAAQP,KAAKI,OAAL,CAAaC,OAAb,CAAqBC,KAA7B,CAAd;;AACA,gCAAME,QAAQF,MAAMG,KAAN,CAAY,yBAAZ,CAAd;AACA,gCAAMC,QAAQC,SAASH,MAAM,CAAN,CAAT,CAAd;AACA,gCAAII,MAAMD,SAASH,MAAM,CAAN,CAAT,CAAV;;AACA,gCAAIK,MAAMD,GAAN,CAAJ,EAAgB;AACZ;AACAA,sCAAOF,QAAQ,KAAKtC,SAAd,GAA2B,CAAjC;;AACA,oCAAIwC,OAAOnC,KAAKqC,IAAhB,EAAsB;AAClBF,0CAAMnC,KAAKqC,IAAL,GAAY,CAAlB;AACH;AACJ;;AACDX,iCAAKY,KAAL,cAAsBL,KAAtB,SAA+BE,GAA/B;AACAZ,iCAAKI,OAAL,CAAaC,OAAb,CAAqBC,KAArB,cAAsCI,KAAtC,SAA+CE,GAA/C;AACH;;AAED,4BAAMI,WAAW,IAAjB;AACA9D,2BAAG+D,SAAH,CAAad,IAAb,EAAmB,UAASZ,KAAT,EAAgB;AAC/B,gCAAIA,KAAJ,EAAW;AACPC,wCAAQD,KAAR,CAAcA,KAAd;;AACA,oCAAI,CAACS,KAAKkB,QAAL,CAAcC,QAAnB,EAA6B;AACzBnB,yCAAKkB,QAAL,CAAcN,GAAd;AACH;AACJ,6BALD,MAKO;AACH;AACA,oCAAIZ,KAAKI,OAAL,CAAaC,OAAb,CAAqBC,KAArB,IAA8B,KAAKc,YAAL,CAAkBf,OAAlB,CAA0B,eAA1B,CAAlC,EAA8E;AAC1E;AACAL,yCAAKI,OAAL,CAAaC,OAAb,CAAqBC,KAArB,GAA6B,KAAKc,YAAL,CAAkBf,OAAlB,CAA0B,eAA1B,EAA2CI,KAA3C,CAAiD,GAAjD,EAAsD,CAAtD,EAAyDY,OAAzD,CAAiE,QAAjE,EAA2E,QAA3E,CAA7B;AACH;;AAED,oCAAMC,aAAa,IAAIlF,OAAOmF,WAAX,EAAnB,CAPG,CAQH;;AACAP,yCAASQ,KAAT,CAAexB,IAAf,EAAqB1B,OAArB,EAA8BA,QAAQE,QAAR,CAAiBE,OAAjB,CAA9B,EAAyDA,OAAzD,EAAkE4C,UAAlE;AACAA,2CAAWV,GAAX,CAAe,KAAKa,IAAL,CAAUvC,IAAzB;AACH;AACJ,yBAlBD;AAoBA,+BAAO,IAAP;AACH,qBA9DqC,CA+DtC;AACA;;;AACA,2BAAO,KAAP;AACH;AAlI2C,aAApB,CAArB;AAqIP;AACA,gBAAMwC,cAAchE,aAAaiE,MAAjC;;AACAjE,yBAAaiE,MAAb,GAAsB,UAASC,MAAT,EAAiB;AACnC,oBAAMC,SAAS,KAAKlC,UAAL,CAAgBmC,IAAhB,CAAqBF,MAArB,CAAf;AACAC,uBAAOE,OAAP,CAAe,UAACzD,OAAD,EAAa;AACxBrC,sBAAEsC,IAAF,CAAOD,QAAQE,QAAf,EAAyB,UAACC,IAAD,EAAU;AAC/B,4BAAIA,QAAQA,KAAKwB,IAAb,IAAqBxB,KAAKwB,IAAL,CAAUC,QAAnC,EAA6C;AACzC;AACAhD,+BAAG8E,YAAH,CAAgB;AACZhD,wCAAQ3B,OAAON,MADH;AAEZkC,qCAAKR,KAAKwB,IAAL,CAAUC;AAFH,6BAAhB,EAGG,UAACX,KAAD,EAAW;AACVjC,sCAAM,YAAM;AACR,wCAAIiC,KAAJ,EAAW;AACPC,gDAAQD,KAAR,CAAcA,KAAd;AACH;AACJ,iCAJD;AAKH,6BATD;AAUH;AACJ,qBAdD;AAeH,iBAhBD,EAFmC,CAoBnC;;AACAmC,4BAAYO,IAAZ,CAAiB,IAAjB,EAAuBL,MAAvB;AACH,aAtBD;AAuBH,SAhLD,MAgLO;AACH,kBAAM,IAAIhG,OAAOsG,KAAX,CAAiB,GAAjB,EAAsB,8BAAtB,CAAN;AACH;AACJ;AACJ","file":"imports/dashboard/product/addNewProduct/imageUploadServer/ProductImage.js.map","sourcesContent":["import { Meteor } from 'meteor/meteor';\nimport { _ } from 'meteor/underscore';\nimport { Random } from 'meteor/random';\nimport { FilesCollection } from 'meteor/ostrio:files';\nimport stream from 'stream';\nimport { Session } from 'meteor/session';\n\nimport S3 from 'aws-sdk/clients/s3'; // http://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/S3.html\n// See fs-extra and graceful-fs NPM packages\n// For better i/o performance\nimport fs from 'fs';\n\nimport { ProjectSettings } from '/imports/dashboard/product/addNewProduct/api/projectSettings.js';\n\n\n\nvar s3Data = ProjectSettings.findOne({\"_id\":\"1\"});\nif(s3Data){\n    process.env.S3='{\"s3\":{\"key\": \"'+ s3Data.key+'\", \"secret\": \"'+ s3Data.secret+'\", \"bucket\": \"'+ s3Data.bucket +'\", \"region\": \"'+s3Data.region+'\"}}' ;\n    \n\n    if (process.env.S3) {\n        Meteor.settings.s3 = JSON.parse(process.env.S3).s3;\n        // console.log(Meteor.settings.s3);\n        const s3Conf = Meteor.settings.s3 || {};\n        const bound  = Meteor.bindEnvironment((callback) => {\n            return callback();\n        });\n\n        // Check settings existence in `Meteor.settings`\n        // This is the best practice for app security\n        if (s3Conf && s3Conf.key && s3Conf.secret && s3Conf.bucket && s3Conf.region) {\n            // Create a new S3 object\n            //s3Conf.secret,\n            //s3Conf.key,\n            //s3Conf.region,\n            const s3 = new S3({\n                secretAccessKey     : s3Conf.secret,\n                accessKeyId         : s3Conf.key,\n                region              : s3Conf.region,\n                // sslEnabled: true, // optional\n                httpOptions: {\n                    timeout : 60000,\n                    agent   : false\n                }\n            });\n\n            // console.log('s3: ', s3);\n            // Declare the Meteor file collection on the Server\n            export const ProductImage = new FilesCollection({\n                debug          : false, // Change to `true` for debugging\n                storagePath    : 'ProductImage',\n                collectionName : 'ProductImage',\n                // Disallow Client to execute remove, use the Meteor.method\n                allowClientCode: false,\n                chunkSize      : 1024 * 1024,\n\n                // Start moving files to AWS:S3\n                // after fully received by the Meteor server\n                onAfterUpload(fileRef) {\n                    // Run through each of the uploaded file\n                    // console.log(\"fileRef2: \", fileRef);\n                    _.each(fileRef.versions, (vRef, version) => {\n                        // We use Random.id() instead of real file's _id\n                        // to secure files from reverse engineering on the AWS client\n\n                        const filePath = 'ProductImage/' + fileRef._id +'.' + fileRef.extension;\n                        // console.log(\"filePath: \", filePath);\n\n                        // Create the AWS:S3 object.\n                        // Feel free to change the storage class from, see the documentation,\n                        // `STANDARD_IA` is the best deal for low access files.\n                        // Key is the file name we are creating on AWS:S3, so it will be like files/XXXXXXXXXXXXXXXXX-original.XXXX\n                        // Body is the file stream we are sending to AWS\n                        s3.putObject({\n                            // ServerSideEncryption: 'AES256', // Optional\n                            StorageClass : 'STANDARD',\n                            Bucket       : s3Conf.bucket,         //s3Conf.bucket,\n                            Key          : filePath,\n                            Body         : fs.createReadStream(vRef.path),\n                            ContentType  : vRef.type,\n                        }, (error) => {\n                            // console.log(\"error: \", error);\n                            bound(() => {\n                                if (error) {\n                                    console.error(error);\n                                } else {\n                                    // Update FilesCollection with link to the file at AWS\n                                    const upd = { $set: {} };\n                                    upd['$set']['versions.' + version + '.meta.pipePath'] = filePath;\n                                    // console.log(\"upd: \", upd);\n\n                                    this.collection.update({\n                                        _id: fileRef._id\n                                    }, upd, (updError) => {\n                                        if (updError) {\n                                            // console.log(\"updError: \", updError);\n                                            console.error(updError);\n                                        } else {\n                                            // Unlink original files from FS after successful upload to AWS:S3\n                                            // console.log(\"unlink: \", fileRef._id);\n                                            this.unlink(this.collection.findOne(fileRef._id), version);\n                                        }\n                                    });\n                                }\n                            });\n                        });\n                    });\n                },\n\n\n                // Intercept access to the file\n                // And redirect request to AWS:S3\n                interceptDownload(http, fileRef, version) {\n                    // console.log('interceptDownload');\n                    let path;\n\n                    if (fileRef && fileRef.versions && fileRef.versions[version] && fileRef.versions[version].meta && fileRef.versions[version].meta.pipePath) {\n                        path = fileRef.versions[version].meta.pipePath;\n                    }\n\n                    if (path) {\n                        // console.log('path ',path);\n                        // If file is successfully moved to AWS:S3\n                        // We will pipe request to AWS:S3\n                        // So, original link will stay always secure\n\n                        // To force ?play and ?download parameters\n                        // and to keep original file name, content-type,\n                        // content-disposition, chunked \"streaming\" and cache-control\n                        // we're using low-level .serve() method\n                        const opts = {\n                            Bucket: s3Conf.bucket,\n                            Key   : path\n                        };\n\n                        if (http.request.headers.range) {\n                            const vRef  = fileRef.versions[version];\n                            let range   = _.clone(http.request.headers.range);\n                            const array = range.split(/bytes=([0-9]*)-([0-9]*)/);\n                            const start = parseInt(array[1]);\n                            let end = parseInt(array[2]);\n                            if (isNaN(end)) {\n                                // Request data from AWS:S3 by small chunks\n                                end = (start + this.chunkSize) - 1;\n                                if (end >= vRef.size) {\n                                    end = vRef.size - 1;\n                                }\n                            }\n                            opts.Range = `bytes=${start}-${end}`;\n                            http.request.headers.range = `bytes=${start}-${end}`;\n                        }\n\n                        const fileColl = this;\n                        s3.getObject(opts, function(error) {\n                            if (error) {\n                                console.error(error);\n                                if (!http.response.finished) {\n                                    http.response.end();\n                                }\n                            } else {\n                                // console.log(opts);\n                                if (http.request.headers.range && this.httpResponse.headers['content-range']) {\n                                    // Set proper range header in according to what is returned from AWS:S3\n                                    http.request.headers.range = this.httpResponse.headers['content-range'].split('/')[0].replace('bytes ', 'bytes=');\n                                }\n\n                                const dataStream = new stream.PassThrough();\n                                // console.warn('fileColl ',fileColl);\n                                fileColl.serve(http, fileRef, fileRef.versions[version], version, dataStream);\n                                dataStream.end(this.data.Body);\n                            }\n                        });\n\n                        return true;\n                    }\n                    // While file is not yet uploaded to AWS:S3\n                    // It will be served file from FS\n                    return false;\n                }\n            });\n\n            // Intercept FilesCollection's remove method to remove file from AWS:S3\n            const _origRemove = ProductImage.remove;\n            ProductImage.remove = function(search) {\n                const cursor = this.collection.find(search);\n                cursor.forEach((fileRef) => {\n                    _.each(fileRef.versions, (vRef) => {\n                        if (vRef && vRef.meta && vRef.meta.pipePath) {\n                            // Remove the object from AWS:S3 first, then we will call the original FilesCollection remove\n                            s3.deleteObject({\n                                Bucket: s3Conf.bucket,\n                                Key: vRef.meta.pipePath,\n                            }, (error) => {\n                                bound(() => {\n                                    if (error) {\n                                        console.error(error);\n                                    }\n                                });\n                            });\n                        }\n                    });\n                });\n\n                //remove original file from database\n                _origRemove.call(this, search);\n            };\n        } else {\n            throw new Meteor.Error(401, 'Missing Meteor file settings');\n        }\n    }\n}\n"]},"hash":"4a89dc5c9e56184cc168670879825eaee7d2ad1b"}
